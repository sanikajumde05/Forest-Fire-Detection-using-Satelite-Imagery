{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943f3dfb-35d8-4caf-9a10-db42fd21e151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 09:37:13.734252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60b485f-21d4-407a-8d70-bf088003fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 images belonging to 2 classes.\n",
      "Found 30250 images belonging to 2 classes.\n",
      "Found 30250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "train_dir = r\"/Users/pramodjumde/Downloads/archive (8)/train\"\n",
    "valid_dir = r\"/Users/pramodjumde/Downloads/archive (8)/test\"\n",
    "test_dir = r\"/Users/pramodjumde/Downloads/archive (8)/valid\"\n",
    "\n",
    "# Set up ImageDataGenerators for Loading images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size = (64, 64), class_mode = 'binary')\n",
    "valid_generator = valid_datagen.flow_from_directory(train_dir, target_size = (64, 64), class_mode = 'binary')\n",
    "test_generator = test_datagen.flow_from_directory(train_dir, target_size = (64, 64), class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b6c163-80ab-4ba4-a9e2-455e349f75d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodjumde/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = 'sigmoid')    # Binary Classification: Wildfire or No Wildfire\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49559cae-ad0a-4160-83d3-efc36fed7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13da8071-d4b2-4ba9-9244-eaace1562081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodjumde/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 455ms/step - accuracy: 0.8706 - loss: 0.2972 - val_accuracy: 0.9361 - val_loss: 0.1715\n",
      "Epoch 2/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 440ms/step - accuracy: 0.9312 - loss: 0.1806 - val_accuracy: 0.9333 - val_loss: 0.1837\n",
      "Epoch 3/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 465ms/step - accuracy: 0.9383 - loss: 0.1673 - val_accuracy: 0.9485 - val_loss: 0.1351\n",
      "Epoch 4/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 430ms/step - accuracy: 0.9480 - loss: 0.1438 - val_accuracy: 0.9233 - val_loss: 0.1959\n",
      "Epoch 5/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 434ms/step - accuracy: 0.9487 - loss: 0.1414 - val_accuracy: 0.9612 - val_loss: 0.1129\n",
      "Epoch 6/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 431ms/step - accuracy: 0.9545 - loss: 0.1224 - val_accuracy: 0.9646 - val_loss: 0.0975\n",
      "Epoch 7/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 448ms/step - accuracy: 0.9574 - loss: 0.1150 - val_accuracy: 0.9706 - val_loss: 0.0816\n",
      "Epoch 8/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 463ms/step - accuracy: 0.9630 - loss: 0.1011 - val_accuracy: 0.9696 - val_loss: 0.0823\n",
      "Epoch 9/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 459ms/step - accuracy: 0.9654 - loss: 0.0936 - val_accuracy: 0.9741 - val_loss: 0.0707\n",
      "Epoch 10/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 455ms/step - accuracy: 0.9695 - loss: 0.0839 - val_accuracy: 0.9803 - val_loss: 0.0594\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data = valid_generator, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86ae041b-3268-4450-898a-eca2e10aebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n"
     ]
    }
   ],
   "source": [
    "def predict_image():\n",
    "    file_path=filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img=Image.open(file_path)\n",
    "        img=img.resize((200,200))\n",
    "        img=ImageTk.PhotoImage(img)\n",
    "        image_label.configure(image=img)\n",
    "        image_label.image=img\n",
    "        img_for_model=Image.open(file_path).resize((64,64))\n",
    "        img_array=np.array(img_for_model)/255.0\n",
    "        img_array=np.expand_dims(img_array,axis=0)\n",
    "        prediction=model.predict(img_array)[0][0]\n",
    "        result=\"Wildfire\" if prediction>0.5 else \"No Wildfire\"\n",
    "        result_label.config(text=\"Prediction: \"+result)\n",
    "root=tk.Tk()\n",
    "root.title(\"Forest Fire Detection\")\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "btn=tk.Button(root,text=\"Upload Image\",command=predict_image)\n",
    "btn.pack(pady=20)\n",
    "\n",
    "image_label=tk.Label(root)\n",
    "image_label.pack()\n",
    "\n",
    "result_label=tk.Label(root,text=\"Prediction: \",font=(\"Helvetica\",16))\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31dc96-e435-48da-a47d-d112dc8974cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
